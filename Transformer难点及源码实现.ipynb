{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b63b13c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b424ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "72ff6795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 4], dtype=torch.int32)\n",
      "[tensor([7, 5]), tensor([4, 7, 4, 6])]\n",
      "[tensor([[6, 2, 0, 0, 0]]), tensor([[5, 7, 1, 5, 0]])]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 考虑source sentence和target sentence，构建序列，序列的字符以其在词表中的索引的形式表示\n",
    "batch_size=2\n",
    "\n",
    "# 单词表大小\n",
    "max_src_num=8\n",
    "max_tgt_num=8\n",
    "model_dim=8\n",
    "\n",
    "# 序列最大长度\n",
    "max_src_len=5\n",
    "max_tgt_len=5\n",
    "\n",
    "# 构造src与tgt尺寸不同的张量，通过后续的padding操作对齐\n",
    "src_len=torch.Tensor([2,4]).to(torch.int32)\n",
    "tgt_len=torch.Tensor([4,3]).to(torch.int32)\n",
    "print(src_len)\n",
    "\n",
    "# 单词索引构成的句子\n",
    "src_seq=[torch.randint(1,max_src_num,(L,)) for L in src_len]\n",
    "tgt_seq=[torch.randint(1,max_tgt_num,(L,)) for L in tgt_len]\n",
    "print(src_seq)\n",
    "# 使用F.pad进行填充\n",
    "src_seq=[F.pad(torch.randint(1,max_src_num,(L,)),(0,max_src_len-L) )for L in src_len]\n",
    "# 输出：[tensor([6, 5, 0, 0, 0]), tensor([1, 6, 3, 7, 0])]\n",
    "src_seq=[torch.unsqueeze(F.pad(torch.randint(1,max_src_num,(L,)),(0,max_src_len-L)),0)\\\n",
    "                   for L in src_len]\n",
    "\n",
    "print(src_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "89bf24ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[7, 1, 0, 0, 0],\n",
      "        [3, 4, 5, 5, 0]])\n"
     ]
    }
   ],
   "source": [
    "# 将其变为二维张量，unsqueese将一维张量（5）变为二维（1,5）\n",
    "src_seq=torch.cat([torch.unsqueeze(F.pad(torch.randint(1,max_src_num,(L,)),(0,max_src_len-L)),0)\\\n",
    "                   for L in src_len],0)\n",
    "print(src_seq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "02edb5e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6, 6, 5, 3, 0],\n",
      "        [7, 4, 1, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# 同理，将target也转为二维张量\n",
    "tgt_seq=torch.cat([torch.unsqueeze(F.pad(torch.randint(1,max_tgt_num,(L,)),(0,max_tgt_len-L)),0)\\\n",
    "                   for L in tgt_len])\n",
    "print(tgt_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360c67aa",
   "metadata": {},
   "source": [
    "## 上述操作利用单词索引构造了源句子和目标句子，并且做了padding，填充值默认为0\n",
    "## 下面进行embedding构造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "5eca3a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.6528,  2.4097,  0.9570,  0.3858, -0.3041,  0.6134,  0.6142,  1.3916,\n",
      "          0.6576,  0.9314, -1.1369,  0.6160,  1.0785,  0.8872, -0.9456, -2.9881],\n",
      "        [-0.5512,  0.4620, -1.7225, -1.8100, -1.2250, -0.1286, -0.4998, -0.3149,\n",
      "         -1.9457,  0.2144, -1.7817,  1.1369, -0.2190,  0.1554, -0.7529,  0.6534],\n",
      "        [ 1.0048, -0.7240, -0.1027, -0.9836, -0.4643, -0.2430,  0.3013,  0.6516,\n",
      "         -0.2913, -0.2158, -0.3863, -0.7110,  1.6927,  0.1301,  0.8376,  0.1422],\n",
      "        [ 1.0934, -1.4516, -0.7795,  0.7219, -1.3705,  0.0106,  0.0246,  0.4021,\n",
      "          1.8732,  0.0562,  3.2037, -0.0233,  0.1952,  1.4447, -0.4063,  0.4728],\n",
      "        [-2.7953, -1.7910, -1.3457, -0.9195,  1.1181,  1.0691, -2.6980, -1.5794,\n",
      "         -0.3142,  1.2090,  1.8347, -0.1617, -0.4771,  0.2918, -2.0525, -0.3232],\n",
      "        [ 1.0037, -0.1365, -0.0463, -0.0243,  1.1619,  0.0221,  1.7008, -2.1778,\n",
      "          0.1995,  0.7878, -1.0047,  1.5440,  0.8991,  1.6637, -1.3616,  0.1457],\n",
      "        [ 2.1714, -0.8621, -1.9771,  0.0185,  1.8364,  1.0167, -0.7294, -0.1742,\n",
      "         -0.0619,  0.1052, -0.3352,  1.2768, -1.0387, -0.7675,  0.4978, -0.2329],\n",
      "        [-1.3553, -1.0042, -0.5770, -0.5233,  0.5627, -0.7605, -1.2845,  1.8573,\n",
      "         -0.8063, -0.1832,  0.9316,  0.5048,  0.4074, -1.3826, -1.5130, -0.1202]],\n",
      "       requires_grad=True)\n",
      "tensor([[7, 1, 0, 0, 0],\n",
      "        [3, 4, 5, 5, 0]])\n",
      "tensor([[[-1.3553, -1.0042, -0.5770, -0.5233,  0.5627, -0.7605, -1.2845,\n",
      "           1.8573, -0.8063, -0.1832,  0.9316,  0.5048,  0.4074, -1.3826,\n",
      "          -1.5130, -0.1202],\n",
      "         [-0.5512,  0.4620, -1.7225, -1.8100, -1.2250, -0.1286, -0.4998,\n",
      "          -0.3149, -1.9457,  0.2144, -1.7817,  1.1369, -0.2190,  0.1554,\n",
      "          -0.7529,  0.6534],\n",
      "         [ 0.6528,  2.4097,  0.9570,  0.3858, -0.3041,  0.6134,  0.6142,\n",
      "           1.3916,  0.6576,  0.9314, -1.1369,  0.6160,  1.0785,  0.8872,\n",
      "          -0.9456, -2.9881],\n",
      "         [ 0.6528,  2.4097,  0.9570,  0.3858, -0.3041,  0.6134,  0.6142,\n",
      "           1.3916,  0.6576,  0.9314, -1.1369,  0.6160,  1.0785,  0.8872,\n",
      "          -0.9456, -2.9881],\n",
      "         [ 0.6528,  2.4097,  0.9570,  0.3858, -0.3041,  0.6134,  0.6142,\n",
      "           1.3916,  0.6576,  0.9314, -1.1369,  0.6160,  1.0785,  0.8872,\n",
      "          -0.9456, -2.9881]],\n",
      "\n",
      "        [[ 1.0934, -1.4516, -0.7795,  0.7219, -1.3705,  0.0106,  0.0246,\n",
      "           0.4021,  1.8732,  0.0562,  3.2037, -0.0233,  0.1952,  1.4447,\n",
      "          -0.4063,  0.4728],\n",
      "         [-2.7953, -1.7910, -1.3457, -0.9195,  1.1181,  1.0691, -2.6980,\n",
      "          -1.5794, -0.3142,  1.2090,  1.8347, -0.1617, -0.4771,  0.2918,\n",
      "          -2.0525, -0.3232],\n",
      "         [ 1.0037, -0.1365, -0.0463, -0.0243,  1.1619,  0.0221,  1.7008,\n",
      "          -2.1778,  0.1995,  0.7878, -1.0047,  1.5440,  0.8991,  1.6637,\n",
      "          -1.3616,  0.1457],\n",
      "         [ 1.0037, -0.1365, -0.0463, -0.0243,  1.1619,  0.0221,  1.7008,\n",
      "          -2.1778,  0.1995,  0.7878, -1.0047,  1.5440,  0.8991,  1.6637,\n",
      "          -1.3616,  0.1457],\n",
      "         [ 0.6528,  2.4097,  0.9570,  0.3858, -0.3041,  0.6134,  0.6142,\n",
      "           1.3916,  0.6576,  0.9314, -1.1369,  0.6160,  1.0785,  0.8872,\n",
      "          -0.9456, -2.9881]]], grad_fn=<EmbeddingBackward>)\n",
      "torch.Size([2, 5, 16])\n"
     ]
    }
   ],
   "source": [
    "# 构造embedding\n",
    "model_dim=16\n",
    "src_embedding_table=nn.Embedding(max_src_num,model_dim)# 调用nn.Embedding中forward得到权重\n",
    "tgt_embedding_table=nn.Embedding(max_tgt_num,model_dim)\n",
    "src_embedding=src_embedding_table(src_seq)\n",
    "tgt_embedding=tgt_embedding_table(tgt_seq)\n",
    "\n",
    "print(src_embedding_table.weight)# 得到一个table，是src词表的权重\n",
    "print(src_seq)# src词表的索引\n",
    "print(src_embedding)# 按照索引取出的权重\n",
    "print(src_embedding.shape)# shape中前两维不变，最后一维由原来的标量变为一维张量，所以维数变为三维\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ca9c29",
   "metadata": {},
   "source": [
    "### 构造PositionEmbedding，其公式如下\n",
    "$$\n",
    "PE_{(pos,2i)}=\\sin\\frac {pos}{10000^{2i/d_{model}}}\\\\\n",
    "PE_{(pos,2i+1)}=\\cos\\frac {pos}{10000^{2i/d_{model}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "d6fc723a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0],\n",
      "        [1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "tensor([[1.0000e+00, 3.1623e+00, 1.0000e+01, 3.1623e+01, 1.0000e+02, 3.1623e+02,\n",
      "         1.0000e+03, 3.1623e+03]])\n"
     ]
    }
   ],
   "source": [
    "pos_mat=torch.arange(max_src_len).reshape((-1,1))\n",
    "i_mat=torch.pow(10000,torch.arange(0,model_dim,2).reshape((1,-1))/model_dim)\n",
    "\n",
    "print(pos_mat)\n",
    "print(i_mat)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "162a4fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "          1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
      "          0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "          1.0000e+00],\n",
      "        [ 8.4147e-01,  5.4030e-01,  3.1098e-01,  9.5042e-01,  9.9833e-02,\n",
      "          9.9500e-01,  3.1618e-02,  9.9950e-01,  9.9998e-03,  9.9995e-01,\n",
      "          3.1623e-03,  9.9999e-01,  1.0000e-03,  1.0000e+00,  3.1623e-04,\n",
      "          1.0000e+00],\n",
      "        [ 9.0930e-01, -4.1615e-01,  5.9113e-01,  8.0658e-01,  1.9867e-01,\n",
      "          9.8007e-01,  6.3203e-02,  9.9800e-01,  1.9999e-02,  9.9980e-01,\n",
      "          6.3245e-03,  9.9998e-01,  2.0000e-03,  1.0000e+00,  6.3246e-04,\n",
      "          1.0000e+00],\n",
      "        [ 1.4112e-01, -9.8999e-01,  8.1265e-01,  5.8275e-01,  2.9552e-01,\n",
      "          9.5534e-01,  9.4726e-02,  9.9550e-01,  2.9995e-02,  9.9955e-01,\n",
      "          9.4867e-03,  9.9995e-01,  3.0000e-03,  1.0000e+00,  9.4868e-04,\n",
      "          1.0000e+00],\n",
      "        [-7.5680e-01, -6.5364e-01,  9.5358e-01,  3.0114e-01,  3.8942e-01,\n",
      "          9.2106e-01,  1.2615e-01,  9.9201e-01,  3.9989e-02,  9.9920e-01,\n",
      "          1.2649e-02,  9.9992e-01,  4.0000e-03,  9.9999e-01,  1.2649e-03,\n",
      "          1.0000e+00]])\n",
      "torch.Size([5, 16])\n"
     ]
    }
   ],
   "source": [
    "# 构建position embedding\n",
    "pe_embedding_table=torch.zeros(max_src_len,model_dim)\n",
    "pe_embedding_table[:,0::2]=torch.sin(pos_mat/i_mat)\n",
    "pe_embedding_table[:,1::2]=torch.cos(pos_mat/i_mat)\n",
    "print(pe_embedding_table)\n",
    "print(pe_embedding_table.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "33da6da0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 16])\n",
      "tensor([[[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "           1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
      "           0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "           1.0000e+00],\n",
      "         [ 8.4147e-01,  5.4030e-01,  3.1098e-01,  9.5042e-01,  9.9833e-02,\n",
      "           9.9500e-01,  3.1618e-02,  9.9950e-01,  9.9998e-03,  9.9995e-01,\n",
      "           3.1623e-03,  9.9999e-01,  1.0000e-03,  1.0000e+00,  3.1623e-04,\n",
      "           1.0000e+00],\n",
      "         [ 9.0930e-01, -4.1615e-01,  5.9113e-01,  8.0658e-01,  1.9867e-01,\n",
      "           9.8007e-01,  6.3203e-02,  9.9800e-01,  1.9999e-02,  9.9980e-01,\n",
      "           6.3245e-03,  9.9998e-01,  2.0000e-03,  1.0000e+00,  6.3246e-04,\n",
      "           1.0000e+00],\n",
      "         [ 1.4112e-01, -9.8999e-01,  8.1265e-01,  5.8275e-01,  2.9552e-01,\n",
      "           9.5534e-01,  9.4726e-02,  9.9550e-01,  2.9995e-02,  9.9955e-01,\n",
      "           9.4867e-03,  9.9995e-01,  3.0000e-03,  1.0000e+00,  9.4868e-04,\n",
      "           1.0000e+00],\n",
      "         [-7.5680e-01, -6.5364e-01,  9.5358e-01,  3.0114e-01,  3.8942e-01,\n",
      "           9.2106e-01,  1.2615e-01,  9.9201e-01,  3.9989e-02,  9.9920e-01,\n",
      "           1.2649e-02,  9.9992e-01,  4.0000e-03,  9.9999e-01,  1.2649e-03,\n",
      "           1.0000e+00]],\n",
      "\n",
      "        [[ 0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "           1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,\n",
      "           0.0000e+00,  1.0000e+00,  0.0000e+00,  1.0000e+00,  0.0000e+00,\n",
      "           1.0000e+00],\n",
      "         [ 8.4147e-01,  5.4030e-01,  3.1098e-01,  9.5042e-01,  9.9833e-02,\n",
      "           9.9500e-01,  3.1618e-02,  9.9950e-01,  9.9998e-03,  9.9995e-01,\n",
      "           3.1623e-03,  9.9999e-01,  1.0000e-03,  1.0000e+00,  3.1623e-04,\n",
      "           1.0000e+00],\n",
      "         [ 9.0930e-01, -4.1615e-01,  5.9113e-01,  8.0658e-01,  1.9867e-01,\n",
      "           9.8007e-01,  6.3203e-02,  9.9800e-01,  1.9999e-02,  9.9980e-01,\n",
      "           6.3245e-03,  9.9998e-01,  2.0000e-03,  1.0000e+00,  6.3246e-04,\n",
      "           1.0000e+00],\n",
      "         [ 1.4112e-01, -9.8999e-01,  8.1265e-01,  5.8275e-01,  2.9552e-01,\n",
      "           9.5534e-01,  9.4726e-02,  9.9550e-01,  2.9995e-02,  9.9955e-01,\n",
      "           9.4867e-03,  9.9995e-01,  3.0000e-03,  1.0000e+00,  9.4868e-04,\n",
      "           1.0000e+00],\n",
      "         [-7.5680e-01, -6.5364e-01,  9.5358e-01,  3.0114e-01,  3.8942e-01,\n",
      "           9.2106e-01,  1.2615e-01,  9.9201e-01,  3.9989e-02,  9.9920e-01,\n",
      "           1.2649e-02,  9.9992e-01,  4.0000e-03,  9.9999e-01,  1.2649e-03,\n",
      "           1.0000e+00]]])\n",
      "torch.Size([2, 5, 16])\n"
     ]
    }
   ],
   "source": [
    "pe_embedding=nn.Embedding(max_src_len,model_dim)\n",
    "pe_embedding.weight=nn.Parameter(pe_embedding_table,requires_grad=False)\n",
    "\n",
    "\n",
    "# src_pe_embedding=pe_embedding(src_seq)# 错误语句，不能传输入索引，而应该传也就是序列的pos\n",
    "src_pos=torch.cat([torch.unsqueeze(torch.arange((max_src_len)),0) for _ in src_len]).to(torch.long)\n",
    "tgt_pos=torch.cat([torch.unsqueeze(torch.arange((max_tgt_len)),0) for _ in tgt_len]).to(torch.long)\n",
    "\n",
    "\n",
    "# 得到position embedding\n",
    "src_pe_embedding=pe_embedding(src_pos)\n",
    "\n",
    "tgt_pe_embedding=pe_embedding(tgt_pos)\n",
    "print(src_pe_embedding.shape)\n",
    "print(tgt_pe_embedding)\n",
    "\n",
    "word_embedding=src_pe_embedding+src_embedding\n",
    "print(word_embedding.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89cb395",
   "metadata": {},
   "source": [
    "### Softmax演示，scale的重要性\n",
    "在attention论文中作者使用scale dot-product attention对$QK^{T}$进行缩放，其主要目的就是为了将其方差固定在1，防止过大的方差导致的权重不平衡（大的越大，小的越小，像下面例子中所演示的）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "957244c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.0004, -0.2448, -1.9298,  1.0693,  0.6463])\n",
      "tensor([0.3211, 0.0924, 0.0171, 0.3440, 0.2253])\n"
     ]
    }
   ],
   "source": [
    "score=torch.randn(5)\n",
    "prob=F.softmax(score,0)\n",
    "print(score)\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "101ee08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2173, 0.1919, 0.1621, 0.2188, 0.2098]) tensor([3.3120e-01, 1.2951e-06, 6.2244e-14, 6.5920e-01, 9.5964e-03])\n"
     ]
    }
   ],
   "source": [
    "# score的缩放在softmax上并不是线性的，而是大的越大小的越小\n",
    "\n",
    "alpha1,alpha2=0.1,10\n",
    "prob1,prob2=F.softmax(score*alpha1,0),F.softmax(score*alpha2,-1)\n",
    "print(prob1,prob2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "48b46f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1701, -0.0417, -0.0352, -0.0476, -0.0456],\n",
      "        [-0.0417,  0.1551, -0.0311, -0.0420, -0.0403],\n",
      "        [-0.0352, -0.0311,  0.1358, -0.0355, -0.0340],\n",
      "        [-0.0476, -0.0420, -0.0355,  0.1710, -0.0459],\n",
      "        [-0.0456, -0.0403, -0.0340, -0.0459,  0.1658]])\n",
      "tensor([[ 2.2151e-01, -4.2895e-07, -2.0616e-14, -2.1833e-01, -3.1784e-03],\n",
      "        [-4.2895e-07,  1.2951e-06, -8.0615e-20, -8.5376e-07, -1.2429e-08],\n",
      "        [-2.0616e-14, -8.0615e-20,  6.2244e-14, -4.1032e-14, -5.9732e-16],\n",
      "        [-2.1833e-01, -8.5376e-07, -4.1032e-14,  2.2466e-01, -6.3260e-03],\n",
      "        [-3.1784e-03, -1.2429e-08, -5.9732e-16, -6.3260e-03,  9.5043e-03]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Conda\\envs\\torch171\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def softmax_func(score):\n",
    "    return F.softmax(score)\n",
    "jaco_mat1=torch.autograd.functional.jacobian(softmax_func,score*alpha1)\n",
    "jaco_mat2=torch.autograd.functional.jacobian(softmax_func,score*alpha2)\n",
    "print(jaco_mat1)\n",
    "print(jaco_mat2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1874cc8",
   "metadata": {},
   "source": [
    "### 构造Encoder的self-attention mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "9d6cc4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.],\n",
      "         [1.],\n",
      "         [0.],\n",
      "         [0.],\n",
      "         [0.]],\n",
      "\n",
      "        [[1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [1.],\n",
      "         [0.]]])\n",
      "torch.Size([2, 5, 1])\n"
     ]
    }
   ],
   "source": [
    "# mask_shape:[batch_size,max_src_len,max_src_len]\n",
    "valid_encoder_pos=torch.unsqueeze(torch.cat([torch.unsqueeze(F.pad(torch.ones(L),(0,max_src_len-L)),0) for L in src_len]),2)\n",
    "print(valid_encoder_pos)\n",
    "print(valid_encoder_pos.shape)\n",
    "# [tensor([1., 1., 0., 0., 0.]), tensor([1., 1., 1., 1., 0.])]\n",
    "# 说明第一个句子有效位置为前两位，第二个句子有效位置为前四位\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "23b3e59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 5])\n",
      "tensor([2, 4], dtype=torch.int32)\n",
      "tensor([[[1., 1., 0., 0., 0.],\n",
      "         [1., 1., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[1., 1., 1., 1., 0.],\n",
      "         [1., 1., 1., 1., 0.],\n",
      "         [1., 1., 1., 1., 0.],\n",
      "         [1., 1., 1., 1., 0.],\n",
      "         [0., 0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "valid_encoder_pos_mat=torch.bmm(valid_encoder_pos,valid_encoder_pos.transpose(1,2))\n",
    "print(valid_encoder_pos_mat.shape)\n",
    "print(src_len)\n",
    "print(valid_encoder_pos_mat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bb6faa",
   "metadata": {},
   "source": [
    "上述第一个样本矩阵的含义：src的句子长度为2，所以有效关联性的第一个单词和一二个单词，而跟三四单词的关联性为0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "79d75d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 1., 1., 1.],\n",
      "         [0., 0., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1., 1.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 1.],\n",
      "         [0., 0., 0., 0., 1.],\n",
      "         [0., 0., 0., 0., 1.],\n",
      "         [0., 0., 0., 0., 1.],\n",
      "         [1., 1., 1., 1., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "invalid_encoder_pos_mat=1-valid_encoder_pos_mat\n",
    "print(invalid_encoder_pos_mat)# 无效矩阵，此时0代表有效1代表无效"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "51611c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[False, False,  True,  True,  True],\n",
      "         [False, False,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True],\n",
      "         [ True,  True,  True,  True,  True]],\n",
      "\n",
      "        [[False, False, False, False,  True],\n",
      "         [False, False, False, False,  True],\n",
      "         [False, False, False, False,  True],\n",
      "         [False, False, False, False,  True],\n",
      "         [ True,  True,  True,  True,  True]]])\n"
     ]
    }
   ],
   "source": [
    "mask_encoder_self_attention=invalid_encoder_pos_mat.to(torch.bool)\n",
    "print(mask_encoder_self_attention)# True代表此位置需要被mask掉，False表示此位置不能被mask掉 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "130466fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.5316, -0.3219,  1.5766,  0.7516, -1.7724],\n",
      "         [ 0.3198, -1.1277, -0.2506,  0.0061, -0.1857],\n",
      "         [ 1.2191, -0.5813, -1.6802,  0.1388, -0.8864],\n",
      "         [-2.3124, -0.5046, -0.5821,  0.6983, -0.1061],\n",
      "         [-0.7098,  1.2676, -0.7041, -0.7373, -2.0713]],\n",
      "\n",
      "        [[ 1.0207, -0.5792, -1.6169, -1.9377,  0.0970],\n",
      "         [-0.0732,  0.1649, -1.2415,  0.8791, -0.7883],\n",
      "         [ 0.8046, -0.2554,  0.9713,  0.6741,  0.5422],\n",
      "         [-0.2889,  1.3921, -1.0500, -0.8623, -1.0440],\n",
      "         [ 0.0082, -0.2510, -0.1469, -0.3241, -0.8230]]])\n",
      "tensor([[[-0.5316, -0.3219,    -inf,    -inf,    -inf],\n",
      "         [ 0.3198, -1.1277,    -inf,    -inf,    -inf],\n",
      "         [   -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "         [   -inf,    -inf,    -inf,    -inf,    -inf],\n",
      "         [   -inf,    -inf,    -inf,    -inf,    -inf]],\n",
      "\n",
      "        [[ 1.0207, -0.5792, -1.6169, -1.9377,    -inf],\n",
      "         [-0.0732,  0.1649, -1.2415,  0.8791,    -inf],\n",
      "         [ 0.8046, -0.2554,  0.9713,  0.6741,    -inf],\n",
      "         [-0.2889,  1.3921, -1.0500, -0.8623,    -inf],\n",
      "         [   -inf,    -inf,    -inf,    -inf,    -inf]]])\n",
      "tensor([[[0.4477, 0.5523, 0.0000, 0.0000, 0.0000],\n",
      "         [0.8096, 0.1904, 0.0000, 0.0000, 0.0000],\n",
      "         [   nan,    nan,    nan,    nan,    nan],\n",
      "         [   nan,    nan,    nan,    nan,    nan],\n",
      "         [   nan,    nan,    nan,    nan,    nan]],\n",
      "\n",
      "        [[0.7545, 0.1523, 0.0540, 0.0392, 0.0000],\n",
      "         [0.1934, 0.2454, 0.0601, 0.5012, 0.0000],\n",
      "         [0.2937, 0.1017, 0.3469, 0.2577, 0.0000],\n",
      "         [0.1351, 0.7256, 0.0631, 0.0761, 0.0000],\n",
      "         [   nan,    nan,    nan,    nan,    nan]]])\n"
     ]
    }
   ],
   "source": [
    "score_demo=torch.randn(batch_size,max_src_len,max_src_len)\n",
    "\n",
    "masked_score=score_demo.masked_fill(mask_encoder_self_attention,-np.inf)\n",
    "p=F.softmax(masked_score,-1)\n",
    "\n",
    "print(score_demo)\n",
    "print(masked_score)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "3c735c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4]])\n",
      "torch.Size([4]) torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3, 4])\n",
    "y=torch.unsqueeze(x,0)\n",
    "print(y)\n",
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0071382c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:torch171] *",
   "language": "python",
   "name": "conda-env-torch171-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
